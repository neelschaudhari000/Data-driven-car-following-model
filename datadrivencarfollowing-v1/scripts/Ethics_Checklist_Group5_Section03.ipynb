{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ethics Checklist\n",
    "## Data Driven Car Following Model\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "## A. Data Collection\n",
    " - [x] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    " <br/>Since this data is publicly available, there is no need of taking consent.\n",
    " - [x] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " <br/>There are no bias in data collection as the data was collected using drones and for every vehicle that comes in the frame and not for any perticular vehicle. Also the data was collected on both Highways and arterial segments hence there is no bias in this.\n",
    " - [x] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    " <br/>Since this data only have trajectory data, no PII was collected which eliminates the risk of PII exposure.\n",
    "\n",
    "## B. Data Storage\n",
    " - [x] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " <br/>As the data is publicaly available, there is no risk of Data security because anyone can get the data from U.S. department of Transportation.\n",
    " - [x] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " <br/>This data do not contain any PII.\n",
    "\n",
    "## C. Analysis\n",
    " - [x] **C.1 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " <br/>There is no biasness in the data.\n",
    " - [x] **C.2 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " <br/> \n",
    " - [x] **C.3 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    " <br/>A repository for the project is created in which all the document related to the data is and will be uplpaded.\n",
    "\n",
    "## D. Modeling\n",
    "**(We have not started working on model creation. Once we start working on this part, we will update the checklist)**\n",
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [ ] **D.5 Communicate bias**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "## E. Deployment\n",
    "**(We have yet to reach the deployment stage. So once we reach this stage, we will update the checklist)**\n",
    " - [ ] **E.1 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.2 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [ ] **E.3 Concept drift**: Do we test and monitor for concept drift to ensure the model remains fair over time?\n",
    " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "*Data Science Ethics Checklist generated with [deon](http://deon.drivendata.org).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "32f9b5c64a9ffdfd44c75ce715a0c18d651d70bac5b5e0fedf911a0bbec25f03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
